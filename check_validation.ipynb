{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "swebench_data_path = \"\"\n",
    "log_root = \"\"\n",
    "validation_logs = defaultdict(lambda: defaultdict(set))\n",
    "swebench_data = pd.read_json(swebench_data_path, lines=True, orient=\"records\")\n",
    "swebench_data_dict = {d[\"instance_id\"]: d for d in swebench_data.to_dict(orient=\"records\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse test results\n",
    "for name in [\"gold\", \"empty\"]:\n",
    "    log_path = os.path.join(log_root, name)\n",
    "    log_dirs = os.listdir(log_path)\n",
    "    \n",
    "    total_logs = len(log_dirs)\n",
    "    missing_logs = 0\n",
    "    print(f\"Processing [{name}] logs\")\n",
    "    pbar = tqdm(total=total_logs)\n",
    "    \n",
    "    for log_dir in log_dirs:\n",
    "        log_file = os.path.join(log_path, log_dir, \"report.json\")\n",
    "        pbar.update(1)\n",
    "        if not os.path.exists(log_file):\n",
    "            missing_logs += 1\n",
    "            pbar.set_postfix({\"missing\": missing_logs, \"total\": total_logs})\n",
    "            continue\n",
    "        with open(log_file, \"r\") as f:\n",
    "            log = json.load(f)\n",
    "        instance_id = list(log.keys())[0]\n",
    "        if \"tests_status\" in log[instance_id]:\n",
    "            validation_logs[instance_id][f\"{name}-pass\"] = set(log[instance_id][\"tests_status\"][\"PASS\"])\n",
    "            validation_logs[instance_id][f\"{name}-fail\"] = set(log[instance_id][\"tests_status\"][\"FAIL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Swe-Bench: we need \"at least one test where it changes from fail to pass\n",
    "validated_instances = []\n",
    "n_total = 0\n",
    "n_validated = 0\n",
    "pbar = tqdm(total=len(validation_logs))\n",
    "for k, log in validation_logs.items():\n",
    "    fail_to_pass = log[\"gold-pass\"] & log[\"empty-fail\"]\n",
    "    pass_to_pass = log[\"gold-pass\"] & log[\"empty-pass\"] \n",
    "    n_total += 1\n",
    "    if len(fail_to_pass) > 0:\n",
    "        n_validated += 1\n",
    "        # print(f\"{k} has test that changes from fail to pass\")\n",
    "        validated_instances.append(swebench_data_dict[k])\n",
    "        validated_instances[-1]['FAIL_TO_PASS'] = list(fail_to_pass)\n",
    "        validated_instances[-1]['PASS_TO_PASS'] = list(pass_to_pass)\n",
    "    pbar.update(1)\n",
    "    pbar.set_postfix({\"validated\": n_validated, \"total\": n_total})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, Value, Sequence, Features\n",
    "KEYS = [\n",
    "    'repo',\n",
    "    'pull_number',\n",
    "    'instance_id',\n",
    "    'issue_numbers',\n",
    "    'base_commit',\n",
    "    'patch',\n",
    "    'test_patch',\n",
    "    'problem_statement',\n",
    "    'hints_text',\n",
    "    'created_at',\n",
    "    'version',\n",
    "    'PASS_TO_PASS',\n",
    "    'FAIL_TO_PASS',\n",
    "]\n",
    "# We need to define feature to make sure the dataset is consistent with the huggingface dataset on the hub\n",
    "FEATURES = Features({\n",
    "    'repo': Value(dtype='string', id=None),\n",
    "    'pull_number': Value(dtype='int64', id=None),\n",
    "    'instance_id': Value(dtype='string', id=None),\n",
    "    'issue_numbers': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
    "    'base_commit': Value(dtype='string', id=None),\n",
    "    'patch': Value(dtype='string', id=None),\n",
    "    'test_patch': Value(dtype='string', id=None),\n",
    "    'problem_statement': Value(dtype='string', id=None),\n",
    "    'hints_text': Value(dtype='string', id=None),\n",
    "    'created_at': Value(dtype='string', id=None),\n",
    "    'version': Value(dtype='string', id=None),\n",
    "    'PASS_TO_PASS': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
    "    'FAIL_TO_PASS': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n",
    "})\n",
    "def to_hf_dataset(data_list):\n",
    "    return Dataset.from_dict({k: [d[k] for d in data_list] for k in KEYS}, features=FEATURES)\n",
    "validated_dataset = to_hf_dataset(validated_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_dataset.push_to_hub(\"\", split=\"\", private=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swebench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
